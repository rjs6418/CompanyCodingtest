{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/11 13:39:36 WARN Utils: Your hostname, gimgeon-uui-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.0.16 instead (on interface en0)\n",
      "22/10/11 13:39:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/11 13:39:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "MAX_MEMORY = \"5g\"\n",
    "spark = SparkSession.builder.appName(\"sql-query\")\\\n",
    "    .config(\"spark.executor.memory\", MAX_MEMORY)\\\n",
    "    .config(\"spark.driver.memory\", MAX_MEMORY)\\\n",
    "    .getOrCreate()\n",
    "    \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+-----+-------+---------------+--------------------+--------------------+--------+-----+\n",
      "|identity_adid| os|model|country|     event_name|              log_id|     server_datetime|quantity|price|\n",
      "+-------------+---+-----+-------+---------------+--------------------+--------------------+--------+-----+\n",
      "|   1028207716|8.9|  8.9|     kr|  custom:battle|ec27d5d4-590a-477...|2018-06-04 08:49:...|    null| null|\n",
      "|    722905290|7.1|  7.1|     kr|  custom:battle|1368cfed-ce95-411...|2018-06-04 17:56:...|    null| null|\n",
      "|   1514811938|3.4|  3.4|     kr|  custom:battle|bf5a0afd-4478-4cf...|2018-06-04 17:59:...|    null| null|\n",
      "|     52925716|6.0|  6.0|     ge|  custom:battle|489d4bf9-1a30-437...|2018-06-04 05:05:...|    null| null|\n",
      "|    620228434|7.1|  7.1|     gb|      abx:login|5231a92e-fa13-4ef...|2018-06-04 05:06:...|    null| null|\n",
      "|    210821615|6.0|  6.0|     us|  abx:firstopen|d4df8648-6b9f-472...|2018-06-04 04:47:...|    null| null|\n",
      "|   1161490770|8.9|  8.9|     us|abx:end_session|35f41d25-3ff2-487...|2018-06-04 04:55:...|    null| null|\n",
      "|   1310149582|8.9|  8.9|     us|      abx:login|7e8d3c2c-84fc-408...|2018-06-04 04:56:...|    null| null|\n",
      "|   2039137755|5.5|  5.5|     ge|  custom:battle|ecdac935-1b6b-4df...|2018-06-04 00:20:...|    null| null|\n",
      "|    635937645|7.1|  7.1|     kr|  custom:battle|0bcc7324-5803-403...|2018-06-04 00:13:...|    null| null|\n",
      "+-------------+---+-----+-------+---------------+--------------------+--------------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+----------------+-------------+\n",
      "|             partner| campaign|     server_datetime|          tracker_id|              log_id|attribution_type|identity_adid|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+----------------+-------------+\n",
      "|                null|     null|2018-05-03 07:19:...|                null|bdb8fc95-4f66-4d1...|               0|    764796223|\n",
      "|                null|     null|2018-05-03 10:25:...|                null|67c41325-a700-4f9...|               0|   2126194985|\n",
      "|                null|     null|2018-05-03 10:26:...|                null|0e41af66-3f17-4bd...|               0|    738518810|\n",
      "|                null|     null|2018-05-03 22:38:...|                null|a5f7ed1f-5d4e-4ad...|               0|    595719449|\n",
      "|                null|     null|2018-05-03 04:14:...|                null|1e1aae33-282d-4dc...|               0|    302402748|\n",
      "|                null|     null|2018-05-03 04:25:...|                null|efee5105-416f-4e7...|               0|   2054238201|\n",
      "|8MCosUQMik2Muvd-M...|campaign1|2018-05-03 04:41:...|Y9zxpa3thkalDcxY4...|ea82fed6-e79b-488...|               0|    604642447|\n",
      "|                null|     null|2018-05-03 21:11:...|                null|c7e6933b-7c64-46e...|               0|    862267407|\n",
      "|                null|     null|2018-05-03 21:26:...|                null|ad073873-02dc-4ef...|               0|    691580676|\n",
      "|                null|     null|2018-05-03 21:29:...|                null|6e8df980-eca6-46c...|               0|   2111418219|\n",
      "+--------------------+---------+--------------------+--------------------+--------------------+----------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "event_parquet_directory = \"/Users/kuno/code/iag/parquet_data/event\"\n",
    "event_df = spark.read.parquet(f\"{event_parquet_directory}\")\n",
    "\n",
    "event_df.show(10)\n",
    "\n",
    "attribution_parquet_directory = \"/Users/kuno/code/iag/parquet_data/attribution\"\n",
    "attribution_df = spark.read.parquet(f\"{attribution_parquet_directory}\")\n",
    "\n",
    "attribution_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('partner', 'string'),\n",
       " ('campaign', 'string'),\n",
       " ('server_datetime', 'string'),\n",
       " ('tracker_id', 'string'),\n",
       " ('log_id', 'string'),\n",
       " ('attribution_type', 'string'),\n",
       " ('identity_adid', 'string')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_df.dtypes\n",
    "attribution_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df.createOrReplaceTempView(\"event\")\n",
    "attribution_df.createOrReplaceTempView(\"attribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+-----+-------+-------------+--------------------+--------------------+--------+-----+\n",
      "|identity_adid| os|model|country|   event_name|              log_id|     server_datetime|quantity|price|\n",
      "+-------------+---+-----+-------+-------------+--------------------+--------------------+--------+-----+\n",
      "|   1028207716|8.9|  8.9|     kr|custom:battle|ec27d5d4-590a-477...|2018-06-04 08:49:...|    null| null|\n",
      "|    722905290|7.1|  7.1|     kr|custom:battle|1368cfed-ce95-411...|2018-06-04 17:56:...|    null| null|\n",
      "|   1514811938|3.4|  3.4|     kr|custom:battle|bf5a0afd-4478-4cf...|2018-06-04 17:59:...|    null| null|\n",
      "|     52925716|6.0|  6.0|     ge|custom:battle|489d4bf9-1a30-437...|2018-06-04 05:05:...|    null| null|\n",
      "|    620228434|7.1|  7.1|     gb|    abx:login|5231a92e-fa13-4ef...|2018-06-04 05:06:...|    null| null|\n",
      "+-------------+---+-----+-------+-------------+--------------------+--------------------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+--------+--------------------+----------+--------------------+----------------+-------------+\n",
      "|partner|campaign|     server_datetime|tracker_id|              log_id|attribution_type|identity_adid|\n",
      "+-------+--------+--------------------+----------+--------------------+----------------+-------------+\n",
      "|   null|    null|2018-05-03 07:19:...|      null|bdb8fc95-4f66-4d1...|               0|    764796223|\n",
      "|   null|    null|2018-05-03 10:25:...|      null|67c41325-a700-4f9...|               0|   2126194985|\n",
      "|   null|    null|2018-05-03 10:26:...|      null|0e41af66-3f17-4bd...|               0|    738518810|\n",
      "|   null|    null|2018-05-03 22:38:...|      null|a5f7ed1f-5d4e-4ad...|               0|    595719449|\n",
      "|   null|    null|2018-05-03 04:14:...|      null|1e1aae33-282d-4dc...|               0|    302402748|\n",
      "+-------+--------+--------------------+----------+--------------------+----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_event = \"SELECT * FROM event\"\n",
    "query_attribution = \"SELECT * FROM attribution\"\n",
    "\n",
    "spark.sql(query_event).show(5)\n",
    "spark.sql(query_attribution).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      Date|ActiveUser|\n",
      "+----------+----------+\n",
      "|2018-05-01|      2830|\n",
      "|2018-05-02|    333893|\n",
      "|2018-05-03|    341539|\n",
      "|2018-05-04|    350451|\n",
      "|2018-05-05|    350957|\n",
      "|2018-05-06|    351161|\n",
      "|2018-05-07|    347310|\n",
      "|2018-05-08|    347407|\n",
      "|2018-05-09|    286317|\n",
      "|2018-05-10|    318275|\n",
      "|2018-05-11|    163929|\n",
      "|2018-05-12|    347605|\n",
      "|2018-05-13|    348300|\n",
      "|2018-05-14|    131192|\n",
      "|2018-05-15|     72188|\n",
      "|2018-05-16|     73165|\n",
      "|2018-05-17|     41765|\n",
      "|2018-05-18|     26393|\n",
      "|2018-05-20|       826|\n",
      "|2018-05-21|    138633|\n",
      "+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 일별 Active User 데이터 추출\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT server_datetime AS Date, \n",
    "       COUNT(DISTINCT identity_adid) AS ActiveUser\n",
    "FROM (SELECT CAST(server_datetime AS DATE), \n",
    "             identity_adid \n",
    "      FROM event\n",
    "      WHERE server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                AND '2018-06-13 23:59:59')\n",
    "GROUP BY server_datetime\n",
    "ORDER BY server_datetime;\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.show()\n",
    "df.write.format(\"csv\").save(\"/Users/kuno/code/iag/result_csv/result-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------+\n",
      "|      Date|ActiveUser|PurchaseAmount|\n",
      "+----------+----------+--------------+\n",
      "|2018-05-01|        47|      118000.0|\n",
      "|2018-05-02|      6233|      1.5529E7|\n",
      "|2018-05-03|      6314|      1.5742E7|\n",
      "|2018-05-04|      6397|      1.6024E7|\n",
      "|2018-05-05|      6429|      1.6088E7|\n",
      "|2018-05-06|      6458|      1.6138E7|\n",
      "|2018-05-07|      6530|      1.6327E7|\n",
      "|2018-05-08|      6574|      1.6472E7|\n",
      "|2018-05-09|      5313|      1.3306E7|\n",
      "|2018-05-10|      5889|      1.4677E7|\n",
      "|2018-05-11|      3045|     7623000.0|\n",
      "|2018-05-12|      6398|      1.5923E7|\n",
      "|2018-05-13|      6303|      1.5782E7|\n",
      "|2018-05-14|     22778|     1.03443E8|\n",
      "|2018-05-15|     31179|     1.46936E8|\n",
      "|2018-05-16|     31490|     1.47298E8|\n",
      "|2018-05-17|     18097|     1.84703E8|\n",
      "|2018-05-18|     10222|     1.08295E8|\n",
      "|2018-05-20|        52|      130000.0|\n",
      "|2018-05-21|     56051|     2.71162E8|\n",
      "+----------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 일별 구매 유저 및 구매 금액 추출\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT server_datetime AS Date, \n",
    "       COUNT(DISTINCT identity_adid) AS ActiveUser, \n",
    "       SUM(price) AS PurchaseAmount\n",
    "FROM (SELECT CAST(server_datetime AS DATE), \n",
    "             identity_adid, \n",
    "             price\n",
    "      FROM event\n",
    "      WHERE (event_name = 'abx:purchase') \n",
    "        AND (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                 AND '2018-06-13 23:59:59'))\n",
    "GROUP BY server_datetime\n",
    "ORDER BY server_datetime;\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.show()\n",
    "df.write.format(\"csv\").save(\"/Users/kuno/code/iag/result_csv/result-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "|            event|ActiveUser|\n",
      "+-----------------+----------+\n",
      "|     abx:purchase|   1131010|\n",
      "|abx:start_session|   3220266|\n",
      "|        abx:login|   2757284|\n",
      "|    abx:firstopen|   3679514|\n",
      "|    custom:battle|   4841266|\n",
      "|  abx:end_session|   2335643|\n",
      "+-----------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 이벤트별 User 데이터 추출\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT event_name AS event,\n",
    "       COUNT(server_datetime) AS ActiveUser\n",
    "FROM (SELECT CAST(server_datetime AS DATE),\n",
    "             event_name\n",
    "      FROM event\n",
    "      WHERE (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                 AND '2018-06-13 23:59:59'))\n",
    "GROUP BY event_name;\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.show()\n",
    "df.write.format(\"csv\").save(\"/Users/kuno/code/iag/result_csv/result-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|campaign_id|ActiveUser|\n",
      "+-----------+----------+\n",
      "|  campaign1|    277843|\n",
      "|  campaign2|    342451|\n",
      "|  campaign3|     75629|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 캠페인별 User 데이터 추출\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT campaign AS campaign_id,\n",
    "       COUNT(identity_adid) AS ActiveUser\n",
    "FROM (SELECT DISTINCT CAST(server_datetime AS DATE),\n",
    "             campaign,\n",
    "             identity_adid\n",
    "      FROM attribution\n",
    "      WHERE (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                 AND '2018-06-13 23:59:59')\n",
    "        AND (NOT campaign IS NULL))\n",
    "GROUP BY campaign\n",
    "ORDER BY campaign;\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.show()\n",
    "df.write.format(\"csv\").save(\"/Users/kuno/code/iag/result_csv/result-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------+\n",
      "|campaign_id|ActiveUser|PurchaseAmount|\n",
      "+-----------+----------+--------------+\n",
      "|  campaign1|    370130|      9.2504E8|\n",
      "|  campaign2|    405550|    1.012998E9|\n",
      "|  campaign3|    180950|     4.52081E8|\n",
      "+-----------+----------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 캠페인별 구매 금액 추출\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT atsub.campaign AS campaign_id,\n",
    "       COUNT(atsub.identity_adid) AS ActiveUser,\n",
    "       SUM(evsub.PersonalPrice) AS PurchaseAmount\n",
    "FROM (SELECT DISTINCT CAST(server_datetime AS DATE) AS Date,\n",
    "                      campaign,\n",
    "                      identity_adid\n",
    "      FROM attribution\n",
    "      WHERE (NOT campaign IS NULL)\n",
    "        AND (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                 AND '2018-06-13 23:59:59')) atsub\n",
    "JOIN (SELECT CAST(server_datetime AS DATE) AS Date, \n",
    "             identity_adid, \n",
    "             SUM(price) AS PersonalPrice\n",
    "      FROM event\n",
    "      WHERE (event_name = 'abx:purchase') \n",
    "        AND (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                 AND '2018-06-13 23:59:59')\n",
    "      GROUP BY server_datetime, identity_adid) evsub\n",
    "ON (atsub.Date = evsub.Date) AND (atsub.identity_adid = evsub.identity_adid)\n",
    "GROUP BY atsub.campaign\n",
    "ORDER BY atsub.campaign;\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.show()\n",
    "df.write.format(\"csv\").save(\"/Users/kuno/code/iag/result_csv/result-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----------+--------------+\n",
      "|country|campaign_id|ActiveUser|PurchaseAmount|\n",
      "+-------+-----------+----------+--------------+\n",
      "|     gb|  campaign1|     73681|     1.84183E8|\n",
      "|     gb|  campaign2|     80882|     2.02007E8|\n",
      "|     gb|  campaign3|     35452|      8.8527E7|\n",
      "|     ge|  campaign1|     36660|      9.1569E7|\n",
      "|     ge|  campaign2|     40468|     1.00975E8|\n",
      "|     ge|  campaign3|     18435|      4.5971E7|\n",
      "|     jp|  campaign1|     75018|     1.87545E8|\n",
      "|     jp|  campaign2|     81890|       2.047E8|\n",
      "|     jp|  campaign3|     36591|      9.1427E7|\n",
      "|     kr|  campaign1|    111304|     2.78094E8|\n",
      "|     kr|  campaign2|    121954|     3.04629E8|\n",
      "|     kr|  campaign3|     54539|     1.36259E8|\n",
      "|     us|  campaign1|     73467|     1.83649E8|\n",
      "|     us|  campaign2|     80356|     2.00687E8|\n",
      "|     us|  campaign3|     35933|      8.9897E7|\n",
      "+-------+-----------+----------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 국가, 캠페인별 구매 금액 추출\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT country AS country,\n",
    "       atsub.campaign AS campaign_id,\n",
    "       COUNT(atsub.identity_adid) AS ActiveUser,\n",
    "       SUM(evsub.PersonalPrice) AS PurchaseAmount\n",
    "FROM (SELECT DISTINCT CAST(server_datetime AS DATE) AS Date,\n",
    "                      campaign,\n",
    "                      identity_adid\n",
    "      FROM attribution\n",
    "      WHERE (NOT campaign IS NULL)\n",
    "        AND (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                 AND '2018-06-13 23:59:59')) atsub\n",
    "LEFT JOIN (SELECT CAST(server_datetime AS DATE) AS Date, \n",
    "             country,\n",
    "             identity_adid, \n",
    "             SUM(price) AS PersonalPrice\n",
    "      FROM event\n",
    "      WHERE (event_name = 'abx:purchase') \n",
    "        AND (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                 AND '2018-06-13 23:59:59')\n",
    "      GROUP BY server_datetime, identity_adid, country) evsub\n",
    "ON (atsub.Date = evsub.Date) AND (atsub.identity_adid = evsub.identity_adid)\n",
    "WHERE NOT country IS NULL\n",
    "GROUP BY country, atsub.campaign\n",
    "ORDER BY country, atsub.campaign;\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.show()\n",
    "df.write.format(\"csv\").save(\"/Users/kuno/code/iag/result_csv/result-6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 61:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+---------+------------+\n",
      "|server_datetime|abx:firstopen|abx:login|abx:purchase|\n",
      "+---------------+-------------+---------+------------+\n",
      "|     2018-05-01|         1387|      386|          47|\n",
      "|     2018-05-02|       161986|    44707|        6233|\n",
      "|     2018-05-03|       166300|    45264|        6314|\n",
      "|     2018-05-04|       170683|    46182|        6397|\n",
      "|     2018-05-05|       170134|    46467|        6429|\n",
      "|     2018-05-06|       169761|    46888|        6458|\n",
      "|     2018-05-07|       168096|    45991|        6530|\n",
      "|     2018-05-08|       168138|    46332|        6574|\n",
      "|     2018-05-09|       139696|    38361|        5314|\n",
      "|     2018-05-10|       154202|    42384|        5889|\n",
      "+---------------+-------------+---------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Funnel 데이터 추출\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM (SELECT server_datetime,\n",
    "             event_name AS event_case,\n",
    "             COUNT(identity_adid) AS ActiveUser\n",
    "      FROM (SELECT CAST(server_datetime AS DATE),\n",
    "                   event_name,\n",
    "                   identity_adid\n",
    "            FROM event\n",
    "            WHERE (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                       AND '2018-06-13 23:59:59'))\n",
    "      GROUP BY server_datetime, event_name)\n",
    "PIVOT (\n",
    "    MAX(ActiveUser)\n",
    "    FOR event_case IN ('abx:firstopen', 'abx:login', 'abx:purchase'))\n",
    "ORDER BY server_datetime;\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.show()\n",
    "df.write.format(\"csv\").save(\"/Users/kuno/code/iag/result_csv/result-7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+--------+\n",
      "|      Date|firstopen| login|purchase|\n",
      "+----------+---------+------+--------+\n",
      "|2018-05-01|     1387|   386|      47|\n",
      "|2018-05-02|   161986| 44707|    6233|\n",
      "|2018-05-03|   166300| 45264|    6314|\n",
      "|2018-05-04|   170683| 46182|    6397|\n",
      "|2018-05-05|   170134| 46467|    6429|\n",
      "|2018-05-06|   169761| 46888|    6458|\n",
      "|2018-05-07|   168096| 45991|    6530|\n",
      "|2018-05-08|   168138| 46332|    6574|\n",
      "|2018-05-09|   139696| 38361|    5313|\n",
      "|2018-05-10|   154202| 42384|    5889|\n",
      "|2018-05-11|    79659| 22031|    3045|\n",
      "|2018-05-12|   169346| 46352|    6398|\n",
      "|2018-05-13|   169504| 46229|    6303|\n",
      "|2018-05-14|    89409| 60316|   22778|\n",
      "|2018-05-15|    72049| 72133|   31179|\n",
      "|2018-05-16|    73041| 73114|   31490|\n",
      "|2018-05-17|    41630| 41713|   18097|\n",
      "|2018-05-18|    26375| 25607|   10222|\n",
      "|2018-05-20|      161|   143|      52|\n",
      "|2018-05-21|    84913|115679|   56051|\n",
      "+----------+---------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Funnel 데이터 추출\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT Date,\n",
    "       count(distinct case when event_name = 'abx:firstopen' \n",
    "         then identity_adid else null end) AS firstopen,\n",
    "       count(distinct case when event_name = 'abx:login' \n",
    "         then identity_adid else null end) AS login,\n",
    "       count(distinct case when event_name = 'abx:purchase' \n",
    "         then identity_adid else null end) AS purchase\n",
    "    \n",
    "FROM (SELECT CAST(server_datetime AS DATE) AS Date,\n",
    "             event_name,\n",
    "             identity_adid\n",
    "      FROM event\n",
    "      WHERE (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                 AND '2018-06-13 23:59:59'))\n",
    "WHERE event_name in ('abx:firstopen', 'abx:login', 'abx:purchase')\n",
    "GROUP BY Date\n",
    "ORDER BY Date\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.show()\n",
    "df.write.format(\"csv\").save(\"/Users/kuno/code/iag/result_csv/result-7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+---------+------+--------+\n",
      "|             partner|newinstalluser|firstopen| login|purchase|\n",
      "+--------------------+--------------+---------+------+--------+\n",
      "|8MCosUQMik2Muvd-M...|       4045059|   533793|258806|   98521|\n",
      "+--------------------+--------------+---------+------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 파트너별 new_install 유저의 funnel 데이터 추출\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT partner,\n",
    "       count(attribution_type) AS newinstalluser,\n",
    "       count(distinct case when event_name = 'abx:firstopen' \n",
    "         then evsub.identity_adid else null end) AS firstopen,\n",
    "       count(distinct case when event_name = 'abx:login' \n",
    "         then evsub.identity_adid else null end) AS login,\n",
    "       count(distinct case when event_name = 'abx:purchase' \n",
    "         then evsub.identity_adid else null end) AS purchase\n",
    "FROM (SELECT event_name,\n",
    "             identity_adid\n",
    "      FROM event\n",
    "      WHERE (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                 AND '2018-06-13 23:59:59')) evsub\n",
    "RIGHT jOIN (SELECT partner, \n",
    "                   identity_adid,\n",
    "                   attribution_type\n",
    "            FROM attribution\n",
    "            WHERE NOT partner IS NULL\n",
    "              AND attribution_type = 0\n",
    "              AND (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                       AND '2018-06-13 23:59:59')) atsub\n",
    "ON evsub.identity_adid = atsub.identity_adid\n",
    "GROUP BY partner    \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.show()\n",
    "df.write.format(\"csv\").save(\"/Users/kuno/code/iag/result_csv/result-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일자별 리텐션\n",
    "query = \"\"\"\n",
    "SELECT re.Date, \n",
    "       COUNT(DISTINCT re.identity_adid), \n",
    "       COUNT(DISTINCT re1.identity_adid), \n",
    "       COUNT(DISTINCT re2.identity_adid),\n",
    "       COUNT(DISTINCT re3.identity_adid),\n",
    "       COUNT(DISTINCT re7.identity_adid)   \n",
    "FROM (SELECT CAST(server_datetime AS DATE) AS Date\n",
    "             , identity_adid\n",
    "      FROM event\n",
    "      WHERE event_name = 'abx:firstopen'\n",
    "      AND (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                               AND '2018-06-10 23:59:59')\n",
    "      ORDER BY Date) re\n",
    "LEFT JOIN (SELECT CAST(server_datetime AS DATE) AS Date\n",
    "                  , identity_adid\n",
    "           FROM event\n",
    "           WHERE event_name = 'abx:firstopen'\n",
    "           AND (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                    AND '2018-06-10 23:59:59')\n",
    "           ORDER BY Date) re1\n",
    "ON (re.identity_adid = re1.identity_adid) and (re.Date = re1.Date + (INTERVAL '-1' DAY))\n",
    "LEFT JOIN (SELECT CAST(server_datetime AS DATE) AS Date\n",
    "                  , identity_adid\n",
    "           FROM event\n",
    "           WHERE event_name = 'abx:firstopen'\n",
    "           AND (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                    AND '2018-06-10 23:59:59')\n",
    "           ORDER BY Date) re2\n",
    "ON (re.identity_adid = re2.identity_adid) and (re.Date = re2.Date + (INTERVAL '-2' DAY))\n",
    "LEFT JOIN (SELECT CAST(server_datetime AS DATE) AS Date\n",
    "                  , identity_adid\n",
    "           FROM event\n",
    "           WHERE event_name = 'abx:firstopen'\n",
    "           AND (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                    AND '2018-06-10 23:59:59')\n",
    "           ORDER BY Date) re3\n",
    "ON (re.identity_adid = re3.identity_adid) and (re.Date = re3.Date + (INTERVAL '-3' DAY))\n",
    "LEFT JOIN (SELECT CAST(server_datetime AS DATE) AS Date\n",
    "                  , identity_adid\n",
    "           FROM event\n",
    "           WHERE event_name = 'abx:firstopen'\n",
    "           AND (server_datetime BETWEEN '2018-05-01 00:00:00' \n",
    "                                    AND '2018-06-10 23:59:59')\n",
    "           ORDER BY Date) re7\n",
    "ON (re.identity_adid = re7.identity_adid) and (re.Date = re7.Date + (INTERVAL '-7' DAY))\n",
    "GROUP BY re.Date\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.show()\n",
    "df.write.format(\"csv\").save(\"/Users/kuno/code/iag/result_csv/result-9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일자별 리텐션\n",
    "query = \"\"\"\n",
    "SELECT DT1.Date, D0, D1, D2, D3, D7\n",
    "FROM   (SELECT re.Date AS Date, \n",
    "               count(distinct re.identity_adid) AS D0,\n",
    "               count(distinct re1.identity_adid) AS D1\n",
    "        FROM (SELECT CAST(server_datetime AS DATE) AS Date\n",
    "                     , identity_adid\n",
    "              FROM event\n",
    "              WHERE event_name = 'abx:firstopen'\n",
    "              AND (server_datetime BETWEEN '2018-05-14 00:00:00' \n",
    "                                       AND '2018-06-10 23:59:59')\n",
    "              ORDER BY Date) re\n",
    "        LEFT JOIN (SELECT CAST(server_datetime AS DATE) AS Date\n",
    "                     , identity_adid\n",
    "                   FROM event\n",
    "                   WHERE event_name = 'abx:firstopen'\n",
    "                   AND (server_datetime BETWEEN '2018-05-14 00:00:00' \n",
    "                                            AND '2018-06-10 23:59:59')\n",
    "                   ORDER BY Date) re1\n",
    "        ON (re.identity_adid = re1.identity_adid) and (re.Date = re1.Date + (INTERVAL '-1' DAY))\n",
    "        GROUP BY re.Date) DT1\n",
    "LEFT JOIN (SELECT re.Date AS Date, \n",
    "                  count(distinct re2.identity_adid) AS D2\n",
    "           FROM (SELECT CAST(server_datetime AS DATE) AS Date\n",
    "                        , identity_adid\n",
    "                 FROM event\n",
    "                 WHERE event_name = 'abx:firstopen'\n",
    "                 AND (server_datetime BETWEEN '2018-05-14 00:00:00' \n",
    "                                          AND '2018-06-10 23:59:59')\n",
    "                 ORDER BY Date) re\n",
    "           LEFT JOIN (SELECT CAST(server_datetime AS DATE) AS Date\n",
    "                        , identity_adid\n",
    "                      FROM event\n",
    "                      WHERE event_name = 'abx:firstopen'\n",
    "                      AND (server_datetime BETWEEN '2018-05-14 00:00:00' \n",
    "                                               AND '2018-06-10 23:59:59')\n",
    "                      ORDER BY Date) re2\n",
    "           ON (re.identity_adid = re2.identity_adid) and (re.Date = re2.Date + (INTERVAL '-2' DAY))\n",
    "           GROUP BY re.Date) DT2\n",
    "ON DT1.Date = DT2.Date\n",
    "LEFT JOIN (SELECT re.Date AS Date, \n",
    "                  count(distinct re3.identity_adid) AS D3\n",
    "           FROM (SELECT CAST(server_datetime AS DATE) AS Date\n",
    "                        , identity_adid\n",
    "                 FROM event\n",
    "                 WHERE event_name = 'abx:firstopen'\n",
    "                 AND (server_datetime BETWEEN '2018-05-14 00:00:00' \n",
    "                                          AND '2018-06-10 23:59:59')\n",
    "                 ORDER BY Date) re\n",
    "           LEFT JOIN (SELECT CAST(server_datetime AS DATE) AS Date\n",
    "                        , identity_adid\n",
    "                      FROM event\n",
    "                      WHERE event_name = 'abx:firstopen'\n",
    "                      AND (server_datetime BETWEEN '2018-05-14 00:00:00' \n",
    "                                               AND '2018-06-10 23:59:59')\n",
    "                      ORDER BY Date) re3\n",
    "           ON (re.identity_adid = re3.identity_adid) and (re.Date = re3.Date + (INTERVAL '-3' DAY))\n",
    "           GROUP BY re.Date) DT3\n",
    "ON DT1.Date = DT3.Date\n",
    "LEFT JOIN (SELECT re.Date AS Date, \n",
    "                  count(distinct re7.identity_adid) AS D7\n",
    "           FROM (SELECT CAST(server_datetime AS DATE) AS Date\n",
    "                        , identity_adid\n",
    "                 FROM event\n",
    "                 WHERE event_name = 'abx:firstopen'\n",
    "                 AND (server_datetime BETWEEN '2018-05-14 00:00:00' \n",
    "                                          AND '2018-06-10 23:59:59')\n",
    "                 ORDER BY Date) re\n",
    "           LEFT JOIN (SELECT CAST(server_datetime AS DATE) AS Date\n",
    "                        , identity_adid\n",
    "                      FROM event\n",
    "                      WHERE event_name = 'abx:firstopen'\n",
    "                      AND (server_datetime BETWEEN '2018-05-14 00:00:00' \n",
    "                                               AND '2018-06-10 23:59:59')\n",
    "                      ORDER BY Date) re7\n",
    "           ON (re.identity_adid = re7.identity_adid) and (re.Date = re7.Date + (INTERVAL '-7' DAY))\n",
    "           GROUP BY re.Date) DT7\n",
    "ON DT1.Date = DT7.Date\n",
    "ORDER BY DT1.Date\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "df = spark.sql(query)\n",
    "df.show()\n",
    "df.write.format(\"csv\").save(\"/Users/kuno/code/iag/result_csv/result-9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b6994fbfc635b831de00e7ed1e58d2dbf80a60c8f648f8869e00a1035c9680e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
